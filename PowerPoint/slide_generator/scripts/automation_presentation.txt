Presentation on internal development of automation tools.

Hello everyone, I've already spoken with many of you about my automation project before, but for those I haven't had the opportunity to, I'm currently trying to automate slide development and evaluation. Before I get started, I do want to take a quick moment to set proper expectations. Firstly, I've only been working on this in my own extra time for my own personal work, and I'm bringing it up to all of you today because I think that it can be extended into our content development team's workflow. Therefore, this is not a finished product; it is not a pretty product, and I know that it could be improved and expanded upon in numerous ways. That's not the point; the point is that our team needs to move forward with generative AI in a more streamlined way, and this is my proposal for how we can do that.  

So, what do I need from you all today? Obviously, feedback on how it can be improved, especially on useability, is always something I'd like to hear, but what's more important at this stage is discussing its efficacy and what has to get done to actually integrate this into the team's workflow. Therefore, what I'd ideally like you to think about is how we can get our developers to work with it as a tool, contribute to the GitHub repo, and identify what work still remains on the human end so that it can be adopted but not blindly trusted.

Firstly, I need to address that there are a lot of tools out there, and I'm sure at least one of you is thinking, what's the point of making our own tools? People are developing products as we speak. But as I said before, my original objective was to make my life easier. I've looked around for different tools, done various free trials, and tried free versions, and perhaps due to a lack of time or attention, I have yet to find a perfect tool that does exactly what I want. And then, on the other hand, I have ChatGPT, which is superb and can do a lot of work for me ... but it can be cumbersome to copy and paste things from ChatGPT to different files and work on formatting, and when it's a redundant task, I have to remind ChatGPT of the role I want it to play. But, at the end of the day, I'm a developer who likes to solve problems, so I decided to solve my own problems.

What I've made is a slide deck generator and a slide deck evaluator.

At a high level, the slide deck generator takes a .txt file as my presentation's script, processes the script so each paragraph is an entry in a JSON file, uses OpenAI to take that script and generate a relevant title, subtitle, and bullet points to go with that paragraph that then becomes my slide notes. I then use that JSON file to create a slide deck and populate all the relevant fields based on our Intel Template Master Slide, which means all of my formatting and fonts have been taken care of. Then, the final step is sending my notes again to OpenAI to create an image description for the image that best accompanies my notes and then using dall-e to create that image. As you may have guessed, this deck was itself generated following that exact process. As a side note, if you're wondering why do we write the script first, it's simply because I like to write and think in documents. So I write out all of my thoughts, I review them, I organize them, I make sure they make sense, and are presented in the most logical sequence, and then I go make slide decks. 

So that's the overall process, and you are currently looking at the results. So, what are the issues to be aware of? The two main issues that we'd need to tackle are: 1. this is a very dry presentation. There's no Smart Art, and I don't know anything about automating Smart Art, so although I feel like it'd be possible, I don't know if it actually is. 2. The thing I'm the most worried about is people generating a deck and not reviewing it. We're already seeing issues where the team submits work that looks like it has generated text because it sounds awkward or out of place since it's missing some context. For example, in the Gen AI course right now, a lot of Jeevan's work had extravagant language like "Delve into the emerging world of generative AI and discover the art and science of prompt engineering." That's a) way too long and b) way too fanciful language, and often this fluffy language isn't actually conveying much information or meaning when it comes to actual slide content. Therefore, there is the risk of an over-dependence on a slide deck generator tool, especially if we can really optimize the slide deck evaluator.

On that note, the slide deck evaluator, again at a high level, takes in a presentation, processes all of the text available on the slide, organizes it into titles, subtitles, content, and notes, and saves all of that into a data frame. It then takes the slide deck submitted and converts each slide into an image. The reason for this is that some of the slide decks use smart art, which, again, is tricky to deal with, so I've made an image version because I can then send that to GPT4_vision to extract the text and evaluate the slide. The entire deck is then evaluated using ChatGPT, and the responses are saved in a CSV file along with all the info so we can identify the slide.

Let's go run it!

Coming back to the presentation. Now that you've seen it working, the next thing to talk about is, of course, the limitations. On the technical front, there are plenty of things I want to improve. Specifically, I want to change the entire process to be run with agents, but all technical performance and prompt performance can be ironed out over time. I think the primary obstacle is the willingness of the team to take feedback from OpenAI, especially if that feedback feels forced. For example, during testing, I often got a response saying think of your color scheme because I said you need to give feedback, but that's not really a very helpful thing to say. So, I've fixed that issue, but there's still the possibility of people reading comments they think are unfair, irrelevant, or unhelpful, which makes them resistant to making changes based on the feedback given.
